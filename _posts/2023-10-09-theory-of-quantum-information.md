---
layout: post
title:  "Beyond Human Experience; Beyond a Single Human's Experience"
subtitle:  "Complexity And The Theory of Quantum Information"
date:   2023-10-09 4:30:00
categories: emergence
---

***Information is physical.*** Information is in the structure of the atom and the chemical bonds that atoms form. It's inside elementary particles of Nature, inside the nuclear fusion of the stars, inside superconductors and dark matter or the structure of DNA that governs the development of Life.  *Information is a* ***physical*** property, but *knowledge is human*. Human knowledge *emerges* from human interaction with information and makes humankind powerful because **knowledge is SHAREABLE.** In fact, it is the *shareability* of human knowledge that gives humankind the capacity for freedom and transcending its circumstances. Shareability is the most essential quality of knowledge ... if we cannot SHARE our knowledge, what good can it possibly be for humans?

Knowledge itself is an extremely complex *thing* resting atop an even more complex foundation ... knowledge is, like beauty, completely in the eye of the beholder or in the hand of the user -- knowledge is way, way, way above and in addition to the extremely simplistic notions underpinning the simplifying assumptions we need to make large language models and vectorized words or symbols even remotely computable ... this human character of knowledge will be there if computation power grows one million-fold or one billion-fold ... human knowledge will expand faster than computation, in part because computation will be constrained by what some human can imagine, although that human will be an *einstein* or a human with intelligence and resources that represents a seemingly superhuman one-in-a-100-million capababilty. Human knowledge is and must be innately SHAREABLE by conscious humans.  

The more complex that knowledge seems to get, the more simple and fundamental the shareable nature of knowledge becomes. We can delve into the experimental implementation to complexity classes, from the philosophical justifications for the [Church-Turing thesis](https://en.wikipedia.org/wiki/Church%E2%80%93Turing_thesis) to the nitty-gritty of [Dirac's bra-ket notation](https://en.wikipedia.org/wiki/Bra%E2%80%93ket_notation) and linear algebraic manipulation on [complex vector spaces](https://en.wikipedia.org/wiki/Real_coordinate_space) ... but we left with an understanding that knowledge is way beyond a clever idea and depends on a clever insight of far more than one *einstein* ... it's not one guy discovering fire, or the wheel or even something like penicillin or the transistor or a quantum computer -- we just are not that smart as individuals, even though we are still stupid enough to file patents that attribute ideas to one individual ... we are getting smarter about knowledge, but we still are not that smart yet when we don't stress sharability.

There are indeed individual human einsteins -- people that bright or as bright as Albert Einstein are rare, but not *that* rare ... yes, it's unlikely that we meet an einstein, even though we might fantasize that the guy in the mirror is an einstein ... maybe only one einstein in 10,000 finds her/his niche in the world ... but still since it's likely that einstein's IQ put him the the 0.03 percentile, if there are 8 billion humans, that means that there about 2.5 million einsteins alive today ... but maybe 250 or 25 of those people are doing OR able to do einstein-level work  ... and COLLECTIVELY humans are getting even smarter than the smartest humans ... but if we don't understand shareability,we are not yet smart enough to understand the limits of intelligence of one human or one machine ... or why humility matters. Perhaps a century ago it still made sense to award Nobel prizes to solo einteins working in obscurity ... but not really any more. *It's the humility, stupid.*

Nowadays, knowledge ***emerges*** from very large populations of *einsteins* arguing with and learning from one another -- but it's not until after the concepts have been is developed by humans ... human knowledge [including the semiotics of how we represent knowledge] does not exist on its own ... 3 and 5 do not know that their sum is 8 or their product is 15; they certainly have no understanding of little rules we use like the commutative property in mathematics ... numerical analysis is terribly important to humans but ONLY to humans [and their numericl machines]... human knowledge is a matter of contexts, but it is a very imperfect, very partial **artifact** of the sum total of all human understanding ... of course, we often say that artificial intelligence is "hallucinating an answer" ... like a free verse rapster riffing on rhymes -- the AI's product is not knowledge and AI functionality or meaningful work product simply cannot extend past the realm of human knowledge, ie after all, exactly WHO is AI trying to be intelligent for?

It's similar for us ... we need to know our WHY ... need to think about WHO we're doing this for? Frankly, it's mostly for us ... or the guy like us who will pick up where we left off in minutes, days or years from now. We are not that smart, we were certainly not born smart ... but collectively, we GET smarter by working on the process of getting smarter.

Before we go any further ...  we should understand not just how little we know but ... how incredibly little it is possible for or our species to ever know. *It's not JUST that we ain't that smart ... it's also that we lack the capacity to ever be more that partially smart.* The complexity of the Universe must be presented in a manner that can be discovered or understood by human beings ... thus, the sum total of all human knowledge and everything that might be accomplished with human knowledge is an infinitesimally small subset of a subset of a subset of what the entire Universe or set of Universes is about. 
 
The philosophical [theory of knowledge](https://en.wikipedia.org/wiki/Epistemology) has offered  a chance to formally think about exactly how knowledge does EMERGE by studying the nature, origin, and scope of knowledge, epistemic justification, the rationality of belief, and various related issues. These ongoing debates in [formal epistemology](https://en.wikipedia.org/wiki/Formal_epistemology) and [computational epistemology](https://en.wikipedia.org/wiki/Computational_epistemology) have traditionally been clustered around four general core areas or themes:

* The philosophical analysis of the nature of knowledge and the conditions required for a belief to constitute knowledge, such as truth, infererence justification and the logical reliability of bodies of knowledge
* Potential inductive and deductive sources of human cognition, acquired knowledge and justified bodies of inference built upon perception, reason, memory, and testimony
* The structure of a body of knowledge, formal learning theory, justified or [statistically learned](https://en.wikipedia.org/wiki/Statistical_learning_theory) belief as well effective procedures or algorithms in [algorithmic learning theory](https://en.wikipedia.org/wiki/Algorithmic_learning_theory), including whether all justified beliefs must be derived from justified foundational beliefs or whether justification requires only a coherent set of beliefs
* Philosophical skepticism, which questions the possibility of knowledge, and related problems, such as whether skepticism poses a threat to our ordinary knowledge claims and when it is possible or necessary to attempt refute skeptical arguments

In an effort to get to a more concrete understanding of information and knowledge, the [Physics of [Quantum] Information and Computation](https://arxiv.org/pdf/2208.08064.pdf) has been a recognized discipline for at least several decades ... this effort has evolved in what can be described as the largely misunderstood, grossly overhyped [because it is so misunderstood] and yet somehow still genuinely important field of Quantum Computation ... the IMPORTANT point to remember is that it's about the Physics of Information -- it's really about thinking about how we accomplish our thinking and computation ... it's not at all like the new release of ChatGPT or large language model OR the C language OR some new gamechanging product or service that people are purchasing and using.

As we think about thinking and the physics of quantum computation, we can frame our thoughts about about this still rapidly evolving field of thought using the structure provided by [Dr. Mark M Wilde's new text in pdf form, but still built *from the ground up* and entitled "From Classical to Quantum Shannon Theory"](https://arxiv.org/pdf/1106.1445.pdf) OR, if you prefer that has influenced lots of people in the field and still current, although developing longer, we can go back to Dr. John Preskil's outline for CalTech's [Phys 219 Quantum Computation](http://theory.caltech.edu/~preskill/ph219/ph219_2023.html)  

1) [Introduction and Overview](http://www.theory.caltech.edu/~preskill/ph229/notes/chap1.pdf)

2) [Foundations I: States and Ensembles](http://www.theory.caltech.edu/~preskill/ph219/chap2_15.pdf)

3) [Foundations II: Measurement and Evolution](http://www.theory.caltech.edu/~preskill/ph219/chap3_15.pdf)

4) [Quantum Entanglement](http://www.theory.caltech.edu/~preskill/ph229/notes/chap4_01.pdf)

5) [Classical and Quantum Circuits](http://www.theory.caltech.edu/~preskill/ph219/chap5_15.pdf)

6) [Quantum Algorithms](http://www.theory.caltech.edu/~preskill/ph219/chap6_20_6A_2022.pdf)

7) [Quantum Error Correction](http://www.theory.caltech.edu/~preskill/ph229/notes/chap7.pdf)

8) [Fault-Tolerant Quantum Computation](https://arxiv.org/pdf/quant-ph/9712048.pdf)

9) [Topological Quantum Computation](http://www.theory.caltech.edu/~preskill/ph219/topological.pdf)

10) [Quantum Shannon Theory](http://www.theory.caltech.edu/~preskill/ph219/chap10_6A_2022.pdf)